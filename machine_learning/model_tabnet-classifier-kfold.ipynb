{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "signal-ozone",
   "metadata": {},
   "source": [
    "Required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developing-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-candy",
   "metadata": {},
   "source": [
    "Cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "emerging-burden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Heberden's node</th>\n",
       "      <th>Murphy's sign</th>\n",
       "      <th>Stahli's line</th>\n",
       "      <th>abdomen acute</th>\n",
       "      <th>abdominal bloating</th>\n",
       "      <th>abdominal tenderness</th>\n",
       "      <th>abnormal sensation</th>\n",
       "      <th>abnormally hard consistency</th>\n",
       "      <th>abortion</th>\n",
       "      <th>...</th>\n",
       "      <th>vision blurred</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>weepiness</th>\n",
       "      <th>weight gain</th>\n",
       "      <th>welt</th>\n",
       "      <th>wheelchair bound</th>\n",
       "      <th>wheezing</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>worry</th>\n",
       "      <th>yellow sputum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hypertensive disease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hypertensive disease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hypertensive disease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hypertensive disease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hypertensive disease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38480</th>\n",
       "      <td>decubitus ulcer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38481</th>\n",
       "      <td>decubitus ulcer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38482</th>\n",
       "      <td>decubitus ulcer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38483</th>\n",
       "      <td>decubitus ulcer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38484</th>\n",
       "      <td>decubitus ulcer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38485 rows × 405 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Disease  Heberden's node  Murphy's sign  Stahli's line  \\\n",
       "0      hypertensive disease                0              0              0   \n",
       "1      hypertensive disease                0              0              0   \n",
       "2      hypertensive disease                0              0              0   \n",
       "3      hypertensive disease                0              0              0   \n",
       "4      hypertensive disease                0              0              0   \n",
       "...                     ...              ...            ...            ...   \n",
       "38480       decubitus ulcer                0              0              0   \n",
       "38481       decubitus ulcer                0              0              0   \n",
       "38482       decubitus ulcer                0              0              0   \n",
       "38483       decubitus ulcer                0              0              0   \n",
       "38484       decubitus ulcer                0              0              0   \n",
       "\n",
       "       abdomen acute  abdominal bloating  abdominal tenderness  \\\n",
       "0                  0                   0                     0   \n",
       "1                  0                   0                     0   \n",
       "2                  0                   0                     0   \n",
       "3                  0                   0                     0   \n",
       "4                  0                   0                     0   \n",
       "...              ...                 ...                   ...   \n",
       "38480              0                   0                     0   \n",
       "38481              0                   0                     0   \n",
       "38482              0                   0                     0   \n",
       "38483              0                   0                     0   \n",
       "38484              0                   0                     0   \n",
       "\n",
       "       abnormal sensation  abnormally hard consistency  abortion  ...  \\\n",
       "0                       0                            0         0  ...   \n",
       "1                       0                            0         0  ...   \n",
       "2                       0                            0         0  ...   \n",
       "3                       0                            0         0  ...   \n",
       "4                       0                            0         0  ...   \n",
       "...                   ...                          ...       ...  ...   \n",
       "38480                   0                            0         0  ...   \n",
       "38481                   0                            0         0  ...   \n",
       "38482                   0                            0         0  ...   \n",
       "38483                   0                            0         0  ...   \n",
       "38484                   0                            0         0  ...   \n",
       "\n",
       "       vision blurred  vomiting  weepiness  weight gain  welt  \\\n",
       "0                   0         0          0            0     0   \n",
       "1                   0         0          0            0     0   \n",
       "2                   0         0          0            0     0   \n",
       "3                   0         0          0            0     0   \n",
       "4                   0         0          0            0     0   \n",
       "...               ...       ...        ...          ...   ...   \n",
       "38480               0         0          0            0     0   \n",
       "38481               0         0          0            0     0   \n",
       "38482               0         0          0            0     0   \n",
       "38483               0         0          0            0     0   \n",
       "38484               0         0          0            0     0   \n",
       "\n",
       "       wheelchair bound  wheezing  withdraw  worry  yellow sputum  \n",
       "0                     0         0         0      0              0  \n",
       "1                     0         0         0      0              0  \n",
       "2                     0         0         0      0              0  \n",
       "3                     0         0         0      0              0  \n",
       "4                     0         0         0      0              0  \n",
       "...                 ...       ...       ...    ...            ...  \n",
       "38480                 0         0         0      0              0  \n",
       "38481                 0         0         0      0              0  \n",
       "38482                 0         0         0      0              0  \n",
       "38483                 0         0         0      0              0  \n",
       "38484                 0         0         0      0              0  \n",
       "\n",
       "[38485 rows x 405 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = './dataset/generated_dataset.csv'\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "permanent-reservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38485 entries, 0 to 38484\n",
      "Columns: 405 entries, Disease to yellow sputum\n",
      "dtypes: int64(404), object(1)\n",
      "memory usage: 118.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-lloyd",
   "metadata": {},
   "source": [
    "Definition of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worthy-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heberden's node</th>\n",
       "      <th>Murphy's sign</th>\n",
       "      <th>Stahli's line</th>\n",
       "      <th>abdomen acute</th>\n",
       "      <th>abdominal bloating</th>\n",
       "      <th>abdominal tenderness</th>\n",
       "      <th>abnormal sensation</th>\n",
       "      <th>abnormally hard consistency</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abscess bacterial</th>\n",
       "      <th>...</th>\n",
       "      <th>vision blurred</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>weepiness</th>\n",
       "      <th>weight gain</th>\n",
       "      <th>welt</th>\n",
       "      <th>wheelchair bound</th>\n",
       "      <th>wheezing</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>worry</th>\n",
       "      <th>yellow sputum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38480</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38481</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38482</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38483</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38484</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38485 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Heberden's node  Murphy's sign  Stahli's line  abdomen acute  \\\n",
       "0                    0              0              0              0   \n",
       "1                    0              0              0              0   \n",
       "2                    0              0              0              0   \n",
       "3                    0              0              0              0   \n",
       "4                    0              0              0              0   \n",
       "...                ...            ...            ...            ...   \n",
       "38480                0              0              0              0   \n",
       "38481                0              0              0              0   \n",
       "38482                0              0              0              0   \n",
       "38483                0              0              0              0   \n",
       "38484                0              0              0              0   \n",
       "\n",
       "       abdominal bloating  abdominal tenderness  abnormal sensation  \\\n",
       "0                       0                     0                   0   \n",
       "1                       0                     0                   0   \n",
       "2                       0                     0                   0   \n",
       "3                       0                     0                   0   \n",
       "4                       0                     0                   0   \n",
       "...                   ...                   ...                 ...   \n",
       "38480                   0                     0                   0   \n",
       "38481                   0                     0                   0   \n",
       "38482                   0                     0                   0   \n",
       "38483                   0                     0                   0   \n",
       "38484                   0                     0                   0   \n",
       "\n",
       "       abnormally hard consistency  abortion  abscess bacterial  ...  \\\n",
       "0                                0         0                  0  ...   \n",
       "1                                0         0                  0  ...   \n",
       "2                                0         0                  0  ...   \n",
       "3                                0         0                  0  ...   \n",
       "4                                0         0                  0  ...   \n",
       "...                            ...       ...                ...  ...   \n",
       "38480                            0         0                  0  ...   \n",
       "38481                            0         0                  0  ...   \n",
       "38482                            0         0                  0  ...   \n",
       "38483                            0         0                  0  ...   \n",
       "38484                            0         0                  0  ...   \n",
       "\n",
       "       vision blurred  vomiting  weepiness  weight gain  welt  \\\n",
       "0                   0         0          0            0     0   \n",
       "1                   0         0          0            0     0   \n",
       "2                   0         0          0            0     0   \n",
       "3                   0         0          0            0     0   \n",
       "4                   0         0          0            0     0   \n",
       "...               ...       ...        ...          ...   ...   \n",
       "38480               0         0          0            0     0   \n",
       "38481               0         0          0            0     0   \n",
       "38482               0         0          0            0     0   \n",
       "38483               0         0          0            0     0   \n",
       "38484               0         0          0            0     0   \n",
       "\n",
       "       wheelchair bound  wheezing  withdraw  worry  yellow sputum  \n",
       "0                     0         0         0      0              0  \n",
       "1                     0         0         0      0              0  \n",
       "2                     0         0         0      0              0  \n",
       "3                     0         0         0      0              0  \n",
       "4                     0         0         0      0              0  \n",
       "...                 ...       ...       ...    ...            ...  \n",
       "38480                 0         0         0      0              0  \n",
       "38481                 0         0         0      0              0  \n",
       "38482                 0         0         0      0              0  \n",
       "38483                 0         0         0      0              0  \n",
       "38484                 0         0         0      0              0  \n",
       "\n",
       "[38485 rows x 404 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.loc[:, df.columns != 'Disease']\n",
    "features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-polish",
   "metadata": {},
   "source": [
    "Definition of dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dynamic-understanding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        hypertensive disease\n",
       "1        hypertensive disease\n",
       "2        hypertensive disease\n",
       "3        hypertensive disease\n",
       "4        hypertensive disease\n",
       "                 ...         \n",
       "38480         decubitus ulcer\n",
       "38481         decubitus ulcer\n",
       "38482         decubitus ulcer\n",
       "38483         decubitus ulcer\n",
       "38484         decubitus ulcer\n",
       "Name: Disease, Length: 38485, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['Disease']\n",
    "target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-sheriff",
   "metadata": {},
   "source": [
    "Splitting the dataset into training, testing, and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authorized-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.80\n",
    "test_ratio = 0.20\n",
    "\n",
    "X, X_test, Y, Y_test = train_test_split(features, target, test_size=(1 - train_ratio), random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-remedy",
   "metadata": {},
   "source": [
    "### Tabnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69257895",
   "metadata": {},
   "source": [
    "Convert all splits to numpy formatted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80d0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "Y = Y.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "Y_test = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c947b5d5",
   "metadata": {},
   "source": [
    "Perform K-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b919d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8803204",
   "metadata": {},
   "source": [
    "Importing the TabNet libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae7236c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_tabnet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7d5ef6",
   "metadata": {},
   "source": [
    "Defining the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4acdcb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "clf1_nopreproc = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                                  optimizer_params=dict(lr=2e-2),\n",
    "                                  scheduler_params={\"step_size\": 10,  # how to use learning rate scheduler\n",
    "                                                    \"gamma\": 0.9},\n",
    "                                  scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                                  mask_type='entmax'  # \"sparsemax\"\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294ac8d",
   "metadata": {},
   "source": [
    "Fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf23150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD: 1\n",
      "epoch 0  | loss: 4.76244 | train_accuracy: 0.06829 | valid_accuracy: 0.07161 |  0:00:08s\n",
      "epoch 1  | loss: 3.62136 | train_accuracy: 0.16529 | valid_accuracy: 0.16223 |  0:00:15s\n",
      "epoch 2  | loss: 2.9229  | train_accuracy: 0.311   | valid_accuracy: 0.31146 |  0:00:22s\n",
      "epoch 3  | loss: 2.03055 | train_accuracy: 0.48226 | valid_accuracy: 0.48084 |  0:00:32s\n",
      "epoch 4  | loss: 1.49355 | train_accuracy: 0.60528 | valid_accuracy: 0.5885  |  0:00:40s\n",
      "epoch 5  | loss: 1.1318  | train_accuracy: 0.65773 | valid_accuracy: 0.64177 |  0:00:47s\n",
      "epoch 6  | loss: 0.91469 | train_accuracy: 0.73272 | valid_accuracy: 0.71111 |  0:00:55s\n",
      "epoch 7  | loss: 0.75478 | train_accuracy: 0.73341 | valid_accuracy: 0.71338 |  0:01:02s\n",
      "epoch 8  | loss: 0.65843 | train_accuracy: 0.76654 | valid_accuracy: 0.74602 |  0:01:10s\n",
      "epoch 9  | loss: 0.59323 | train_accuracy: 0.79184 | valid_accuracy: 0.76941 |  0:01:17s\n",
      "epoch 10 | loss: 0.53933 | train_accuracy: 0.80487 | valid_accuracy: 0.7837  |  0:01:24s\n",
      "epoch 11 | loss: 0.49733 | train_accuracy: 0.80702 | valid_accuracy: 0.77785 |  0:01:32s\n",
      "epoch 12 | loss: 0.46779 | train_accuracy: 0.81527 | valid_accuracy: 0.7897  |  0:01:39s\n",
      "epoch 13 | loss: 0.45985 | train_accuracy: 0.81673 | valid_accuracy: 0.78776 |  0:01:47s\n",
      "epoch 14 | loss: 0.41501 | train_accuracy: 0.83053 | valid_accuracy: 0.79782 |  0:01:54s\n",
      "epoch 15 | loss: 0.40254 | train_accuracy: 0.82379 | valid_accuracy: 0.80172 |  0:02:01s\n",
      "epoch 16 | loss: 0.40601 | train_accuracy: 0.82992 | valid_accuracy: 0.80237 |  0:02:09s\n",
      "epoch 17 | loss: 0.38086 | train_accuracy: 0.82696 | valid_accuracy: 0.79799 |  0:02:17s\n",
      "epoch 18 | loss: 0.37963 | train_accuracy: 0.83873 | valid_accuracy: 0.80935 |  0:02:24s\n",
      "epoch 19 | loss: 0.35793 | train_accuracy: 0.84198 | valid_accuracy: 0.81617 |  0:02:32s\n",
      "epoch 20 | loss: 0.35605 | train_accuracy: 0.83561 | valid_accuracy: 0.80188 |  0:02:39s\n",
      "epoch 21 | loss: 0.34473 | train_accuracy: 0.84361 | valid_accuracy: 0.80854 |  0:02:47s\n",
      "epoch 22 | loss: 0.32062 | train_accuracy: 0.84629 | valid_accuracy: 0.82186 |  0:02:54s\n",
      "epoch 23 | loss: 0.31563 | train_accuracy: 0.84945 | valid_accuracy: 0.82251 |  0:03:02s\n",
      "epoch 24 | loss: 0.32292 | train_accuracy: 0.84998 | valid_accuracy: 0.82137 |  0:03:09s\n",
      "epoch 25 | loss: 0.32282 | train_accuracy: 0.85164 | valid_accuracy: 0.81942 |  0:03:16s\n",
      "epoch 26 | loss: 0.30295 | train_accuracy: 0.84957 | valid_accuracy: 0.82056 |  0:03:24s\n",
      "epoch 27 | loss: 0.29951 | train_accuracy: 0.84612 | valid_accuracy: 0.81358 |  0:03:31s\n",
      "epoch 28 | loss: 0.30289 | train_accuracy: 0.8449  | valid_accuracy: 0.81179 |  0:03:39s\n",
      "epoch 29 | loss: 0.30536 | train_accuracy: 0.84917 | valid_accuracy: 0.81423 |  0:03:46s\n",
      "epoch 30 | loss: 0.29054 | train_accuracy: 0.85371 | valid_accuracy: 0.8165  |  0:03:53s\n",
      "epoch 31 | loss: 0.27405 | train_accuracy: 0.84507 | valid_accuracy: 0.81276 |  0:04:01s\n",
      "epoch 32 | loss: 0.27922 | train_accuracy: 0.85124 | valid_accuracy: 0.81455 |  0:04:08s\n",
      "epoch 33 | loss: 0.27326 | train_accuracy: 0.86041 | valid_accuracy: 0.82023 |  0:04:15s\n",
      "epoch 34 | loss: 0.27226 | train_accuracy: 0.85392 | valid_accuracy: 0.81585 |  0:04:23s\n",
      "epoch 35 | loss: 0.27267 | train_accuracy: 0.85838 | valid_accuracy: 0.82738 |  0:04:30s\n",
      "epoch 36 | loss: 0.26836 | train_accuracy: 0.86074 | valid_accuracy: 0.83193 |  0:04:38s\n",
      "epoch 37 | loss: 0.25862 | train_accuracy: 0.86541 | valid_accuracy: 0.83014 |  0:04:46s\n",
      "epoch 38 | loss: 0.26592 | train_accuracy: 0.86342 | valid_accuracy: 0.82754 |  0:04:53s\n",
      "epoch 39 | loss: 0.24676 | train_accuracy: 0.86163 | valid_accuracy: 0.8152  |  0:05:00s\n",
      "epoch 40 | loss: 0.25752 | train_accuracy: 0.86147 | valid_accuracy: 0.81991 |  0:05:08s\n",
      "epoch 41 | loss: 0.25257 | train_accuracy: 0.86248 | valid_accuracy: 0.83079 |  0:05:15s\n",
      "epoch 42 | loss: 0.24273 | train_accuracy: 0.86289 | valid_accuracy: 0.82429 |  0:05:23s\n",
      "epoch 43 | loss: 0.24334 | train_accuracy: 0.86606 | valid_accuracy: 0.83063 |  0:05:30s\n",
      "epoch 44 | loss: 0.25379 | train_accuracy: 0.86504 | valid_accuracy: 0.82186 |  0:05:37s\n",
      "epoch 45 | loss: 0.25132 | train_accuracy: 0.85457 | valid_accuracy: 0.81146 |  0:05:45s\n",
      "epoch 46 | loss: 0.2454  | train_accuracy: 0.86955 | valid_accuracy: 0.82868 |  0:05:52s\n",
      "epoch 47 | loss: 0.23832 | train_accuracy: 0.86451 | valid_accuracy: 0.82429 |  0:05:59s\n",
      "epoch 48 | loss: 0.23852 | train_accuracy: 0.86391 | valid_accuracy: 0.82657 |  0:06:07s\n",
      "epoch 49 | loss: 0.2396  | train_accuracy: 0.86659 | valid_accuracy: 0.82202 |  0:06:14s\n",
      "epoch 50 | loss: 0.24005 | train_accuracy: 0.86829 | valid_accuracy: 0.82981 |  0:06:21s\n",
      "epoch 51 | loss: 0.22379 | train_accuracy: 0.86967 | valid_accuracy: 0.82689 |  0:06:29s\n",
      "epoch 52 | loss: 0.22262 | train_accuracy: 0.86914 | valid_accuracy: 0.82511 |  0:06:36s\n",
      "epoch 53 | loss: 0.22164 | train_accuracy: 0.8676  | valid_accuracy: 0.82478 |  0:06:43s\n",
      "epoch 54 | loss: 0.22097 | train_accuracy: 0.87117 | valid_accuracy: 0.8277  |  0:06:51s\n",
      "epoch 55 | loss: 0.22425 | train_accuracy: 0.87231 | valid_accuracy: 0.82511 |  0:06:58s\n",
      "epoch 56 | loss: 0.2247  | train_accuracy: 0.87203 | valid_accuracy: 0.82868 |  0:07:06s\n",
      "epoch 57 | loss: 0.2256  | train_accuracy: 0.8689  | valid_accuracy: 0.81877 |  0:07:13s\n",
      "epoch 58 | loss: 0.21199 | train_accuracy: 0.86963 | valid_accuracy: 0.82397 |  0:07:21s\n",
      "epoch 59 | loss: 0.22716 | train_accuracy: 0.8676  | valid_accuracy: 0.82527 |  0:07:28s\n",
      "epoch 60 | loss: 0.20156 | train_accuracy: 0.87158 | valid_accuracy: 0.82852 |  0:07:36s\n",
      "epoch 61 | loss: 0.20792 | train_accuracy: 0.87369 | valid_accuracy: 0.82007 |  0:07:43s\n",
      "epoch 62 | loss: 0.20911 | train_accuracy: 0.8732  | valid_accuracy: 0.82267 |  0:07:50s\n",
      "epoch 63 | loss: 0.1987  | train_accuracy: 0.87077 | valid_accuracy: 0.83176 |  0:07:58s\n",
      "epoch 64 | loss: 0.2056  | train_accuracy: 0.87462 | valid_accuracy: 0.8264  |  0:08:05s\n",
      "epoch 65 | loss: 0.20934 | train_accuracy: 0.87365 | valid_accuracy: 0.82121 |  0:08:12s\n",
      "epoch 66 | loss: 0.20934 | train_accuracy: 0.87247 | valid_accuracy: 0.8277  |  0:08:20s\n",
      "epoch 67 | loss: 0.20841 | train_accuracy: 0.8771  | valid_accuracy: 0.83014 |  0:08:27s\n",
      "epoch 68 | loss: 0.21417 | train_accuracy: 0.87024 | valid_accuracy: 0.82267 |  0:08:34s\n",
      "epoch 69 | loss: 0.20506 | train_accuracy: 0.8773  | valid_accuracy: 0.83582 |  0:08:42s\n",
      "epoch 70 | loss: 0.19056 | train_accuracy: 0.87795 | valid_accuracy: 0.82852 |  0:08:49s\n",
      "epoch 71 | loss: 0.1978  | train_accuracy: 0.87572 | valid_accuracy: 0.82852 |  0:08:57s\n",
      "epoch 72 | loss: 0.20159 | train_accuracy: 0.87337 | valid_accuracy: 0.82592 |  0:09:04s\n",
      "epoch 73 | loss: 0.19059 | train_accuracy: 0.87771 | valid_accuracy: 0.82835 |  0:09:11s\n",
      "epoch 74 | loss: 0.18978 | train_accuracy: 0.8771  | valid_accuracy: 0.83144 |  0:09:19s\n",
      "epoch 75 | loss: 0.19116 | train_accuracy: 0.87905 | valid_accuracy: 0.82754 |  0:09:26s\n",
      "epoch 76 | loss: 0.21016 | train_accuracy: 0.87527 | valid_accuracy: 0.83128 |  0:09:33s\n",
      "epoch 77 | loss: 0.1934  | train_accuracy: 0.87771 | valid_accuracy: 0.82592 |  0:09:41s\n",
      "epoch 78 | loss: 0.18969 | train_accuracy: 0.88063 | valid_accuracy: 0.83647 |  0:09:48s\n",
      "epoch 79 | loss: 0.19231 | train_accuracy: 0.87767 | valid_accuracy: 0.8277  |  0:09:56s\n",
      "epoch 80 | loss: 0.1894  | train_accuracy: 0.87739 | valid_accuracy: 0.82364 |  0:10:03s\n",
      "epoch 81 | loss: 0.18362 | train_accuracy: 0.88108 | valid_accuracy: 0.83566 |  0:10:10s\n",
      "epoch 82 | loss: 0.1913  | train_accuracy: 0.87564 | valid_accuracy: 0.82316 |  0:10:18s\n",
      "epoch 83 | loss: 0.19211 | train_accuracy: 0.87844 | valid_accuracy: 0.82722 |  0:10:25s\n",
      "epoch 84 | loss: 0.18811 | train_accuracy: 0.8784  | valid_accuracy: 0.83355 |  0:10:32s\n",
      "epoch 85 | loss: 0.18128 | train_accuracy: 0.88051 | valid_accuracy: 0.83404 |  0:10:40s\n",
      "epoch 86 | loss: 0.18473 | train_accuracy: 0.87864 | valid_accuracy: 0.83306 |  0:10:47s\n",
      "epoch 87 | loss: 0.18174 | train_accuracy: 0.87832 | valid_accuracy: 0.8277  |  0:10:55s\n",
      "epoch 88 | loss: 0.18179 | train_accuracy: 0.87714 | valid_accuracy: 0.82543 |  0:11:02s\n",
      "epoch 89 | loss: 0.18021 | train_accuracy: 0.8797  | valid_accuracy: 0.82787 |  0:11:09s\n",
      "epoch 90 | loss: 0.18361 | train_accuracy: 0.8767  | valid_accuracy: 0.82186 |  0:11:17s\n",
      "epoch 91 | loss: 0.16688 | train_accuracy: 0.88047 | valid_accuracy: 0.83452 |  0:11:24s\n",
      "epoch 92 | loss: 0.17209 | train_accuracy: 0.88112 | valid_accuracy: 0.83323 |  0:11:31s\n",
      "epoch 93 | loss: 0.17231 | train_accuracy: 0.88132 | valid_accuracy: 0.82413 |  0:11:39s\n",
      "epoch 94 | loss: 0.17918 | train_accuracy: 0.87909 | valid_accuracy: 0.8329  |  0:11:46s\n",
      "epoch 95 | loss: 0.18836 | train_accuracy: 0.87893 | valid_accuracy: 0.83225 |  0:11:53s\n",
      "epoch 96 | loss: 0.1753  | train_accuracy: 0.88104 | valid_accuracy: 0.83452 |  0:12:01s\n",
      "epoch 97 | loss: 0.16785 | train_accuracy: 0.87799 | valid_accuracy: 0.83111 |  0:12:08s\n",
      "epoch 98 | loss: 0.1795  | train_accuracy: 0.87881 | valid_accuracy: 0.83176 |  0:12:16s\n",
      "epoch 99 | loss: 0.1662  | train_accuracy: 0.88388 | valid_accuracy: 0.83225 |  0:12:23s\n",
      "epoch 100| loss: 0.17665 | train_accuracy: 0.88262 | valid_accuracy: 0.83436 |  0:12:30s\n",
      "epoch 101| loss: 0.17349 | train_accuracy: 0.87848 | valid_accuracy: 0.82884 |  0:12:38s\n",
      "epoch 102| loss: 0.17093 | train_accuracy: 0.87921 | valid_accuracy: 0.82998 |  0:12:45s\n",
      "epoch 103| loss: 0.18046 | train_accuracy: 0.8825  | valid_accuracy: 0.83615 |  0:12:53s\n",
      "epoch 104| loss: 0.16371 | train_accuracy: 0.87848 | valid_accuracy: 0.8303  |  0:13:00s\n",
      "epoch 105| loss: 0.17322 | train_accuracy: 0.88518 | valid_accuracy: 0.82852 |  0:13:07s\n",
      "epoch 106| loss: 0.16027 | train_accuracy: 0.87885 | valid_accuracy: 0.83144 |  0:13:15s\n",
      "epoch 107| loss: 0.17372 | train_accuracy: 0.87954 | valid_accuracy: 0.829   |  0:13:22s\n",
      "epoch 108| loss: 0.16257 | train_accuracy: 0.88226 | valid_accuracy: 0.83501 |  0:13:30s\n",
      "epoch 109| loss: 0.17435 | train_accuracy: 0.88051 | valid_accuracy: 0.82819 |  0:13:37s\n",
      "epoch 110| loss: 0.16863 | train_accuracy: 0.88153 | valid_accuracy: 0.82933 |  0:13:44s\n",
      "epoch 111| loss: 0.16797 | train_accuracy: 0.88587 | valid_accuracy: 0.83339 |  0:13:52s\n",
      "epoch 112| loss: 0.16712 | train_accuracy: 0.88193 | valid_accuracy: 0.83014 |  0:13:59s\n",
      "epoch 113| loss: 0.15583 | train_accuracy: 0.88234 | valid_accuracy: 0.82689 |  0:14:07s\n",
      "epoch 114| loss: 0.17108 | train_accuracy: 0.88477 | valid_accuracy: 0.83323 |  0:14:14s\n",
      "epoch 115| loss: 0.16191 | train_accuracy: 0.88108 | valid_accuracy: 0.82738 |  0:14:22s\n",
      "epoch 116| loss: 0.15976 | train_accuracy: 0.88502 | valid_accuracy: 0.83306 |  0:14:29s\n",
      "epoch 117| loss: 0.16022 | train_accuracy: 0.88705 | valid_accuracy: 0.83436 |  0:14:36s\n",
      "epoch 118| loss: 0.1591  | train_accuracy: 0.88181 | valid_accuracy: 0.83485 |  0:14:44s\n",
      "epoch 119| loss: 0.16383 | train_accuracy: 0.88327 | valid_accuracy: 0.83323 |  0:14:51s\n",
      "epoch 120| loss: 0.15756 | train_accuracy: 0.88469 | valid_accuracy: 0.83128 |  0:14:59s\n",
      "epoch 121| loss: 0.1526  | train_accuracy: 0.88396 | valid_accuracy: 0.82965 |  0:15:06s\n",
      "epoch 122| loss: 0.15493 | train_accuracy: 0.88782 | valid_accuracy: 0.83193 |  0:15:14s\n",
      "epoch 123| loss: 0.14614 | train_accuracy: 0.88514 | valid_accuracy: 0.82397 |  0:15:21s\n",
      "epoch 124| loss: 0.15962 | train_accuracy: 0.88498 | valid_accuracy: 0.82754 |  0:15:29s\n",
      "epoch 125| loss: 0.16104 | train_accuracy: 0.88372 | valid_accuracy: 0.82835 |  0:15:36s\n",
      "epoch 126| loss: 0.15817 | train_accuracy: 0.88376 | valid_accuracy: 0.82689 |  0:15:43s\n",
      "epoch 127| loss: 0.15341 | train_accuracy: 0.88299 | valid_accuracy: 0.82819 |  0:15:51s\n",
      "epoch 128| loss: 0.16012 | train_accuracy: 0.88514 | valid_accuracy: 0.83079 |  0:15:58s\n",
      "\n",
      "Early stopping occurred at epoch 128 with best_epoch = 78 and best_valid_accuracy = 0.83647\n",
      "Best weights from best epoch are automatically used!\n",
      "K-FOLD: 2\n",
      "epoch 0  | loss: 0.34105 | train_accuracy: 0.79631 | valid_accuracy: 0.79912 |  0:00:07s\n",
      "epoch 1  | loss: 0.29233 | train_accuracy: 0.85684 | valid_accuracy: 0.85434 |  0:00:14s\n",
      "epoch 2  | loss: 0.28488 | train_accuracy: 0.86045 | valid_accuracy: 0.84833 |  0:00:22s\n",
      "epoch 3  | loss: 0.27586 | train_accuracy: 0.85871 | valid_accuracy: 0.84297 |  0:00:29s\n",
      "epoch 4  | loss: 0.27579 | train_accuracy: 0.84547 | valid_accuracy: 0.83079 |  0:00:36s\n",
      "epoch 5  | loss: 0.27507 | train_accuracy: 0.86131 | valid_accuracy: 0.84605 |  0:00:44s\n",
      "epoch 6  | loss: 0.25468 | train_accuracy: 0.86151 | valid_accuracy: 0.84898 |  0:00:51s\n",
      "epoch 7  | loss: 0.26472 | train_accuracy: 0.86646 | valid_accuracy: 0.85158 |  0:00:59s\n",
      "epoch 8  | loss: 0.24283 | train_accuracy: 0.86488 | valid_accuracy: 0.84053 |  0:01:06s\n",
      "epoch 9  | loss: 0.2437  | train_accuracy: 0.86577 | valid_accuracy: 0.84248 |  0:01:13s\n",
      "epoch 10 | loss: 0.24479 | train_accuracy: 0.87048 | valid_accuracy: 0.84557 |  0:01:21s\n",
      "epoch 11 | loss: 0.23782 | train_accuracy: 0.86269 | valid_accuracy: 0.83566 |  0:01:28s\n",
      "epoch 12 | loss: 0.23562 | train_accuracy: 0.86387 | valid_accuracy: 0.83761 |  0:01:35s\n",
      "epoch 13 | loss: 0.22216 | train_accuracy: 0.87121 | valid_accuracy: 0.84719 |  0:01:43s\n",
      "epoch 14 | loss: 0.23195 | train_accuracy: 0.86468 | valid_accuracy: 0.84151 |  0:01:50s\n",
      "epoch 15 | loss: 0.22354 | train_accuracy: 0.87036 | valid_accuracy: 0.83647 |  0:01:57s\n",
      "epoch 16 | loss: 0.22537 | train_accuracy: 0.86821 | valid_accuracy: 0.8329  |  0:02:05s\n",
      "epoch 17 | loss: 0.21861 | train_accuracy: 0.86663 | valid_accuracy: 0.83599 |  0:02:12s\n",
      "epoch 18 | loss: 0.21843 | train_accuracy: 0.86703 | valid_accuracy: 0.83323 |  0:02:19s\n",
      "epoch 19 | loss: 0.21578 | train_accuracy: 0.86175 | valid_accuracy: 0.82949 |  0:02:27s\n",
      "epoch 20 | loss: 0.21944 | train_accuracy: 0.86748 | valid_accuracy: 0.83404 |  0:02:34s\n",
      "epoch 21 | loss: 0.21827 | train_accuracy: 0.86874 | valid_accuracy: 0.83517 |  0:02:42s\n",
      "epoch 22 | loss: 0.21807 | train_accuracy: 0.87349 | valid_accuracy: 0.84427 |  0:02:49s\n",
      "epoch 23 | loss: 0.20941 | train_accuracy: 0.87454 | valid_accuracy: 0.8303  |  0:02:56s\n",
      "epoch 24 | loss: 0.20744 | train_accuracy: 0.87402 | valid_accuracy: 0.83728 |  0:03:03s\n",
      "epoch 25 | loss: 0.21112 | train_accuracy: 0.87247 | valid_accuracy: 0.82965 |  0:03:11s\n",
      "epoch 26 | loss: 0.21404 | train_accuracy: 0.87369 | valid_accuracy: 0.83534 |  0:03:18s\n",
      "epoch 27 | loss: 0.22179 | train_accuracy: 0.87328 | valid_accuracy: 0.83956 |  0:03:25s\n",
      "epoch 28 | loss: 0.21284 | train_accuracy: 0.86918 | valid_accuracy: 0.82981 |  0:03:33s\n",
      "epoch 29 | loss: 0.20089 | train_accuracy: 0.87771 | valid_accuracy: 0.84021 |  0:03:40s\n",
      "epoch 30 | loss: 0.19819 | train_accuracy: 0.87625 | valid_accuracy: 0.83485 |  0:03:48s\n",
      "epoch 31 | loss: 0.19655 | train_accuracy: 0.87568 | valid_accuracy: 0.82803 |  0:03:55s\n",
      "epoch 32 | loss: 0.19844 | train_accuracy: 0.87337 | valid_accuracy: 0.83858 |  0:04:02s\n",
      "epoch 33 | loss: 0.19185 | train_accuracy: 0.87629 | valid_accuracy: 0.83664 |  0:04:10s\n",
      "epoch 34 | loss: 0.19756 | train_accuracy: 0.88031 | valid_accuracy: 0.83517 |  0:04:17s\n",
      "epoch 35 | loss: 0.19961 | train_accuracy: 0.87523 | valid_accuracy: 0.83371 |  0:04:24s\n",
      "epoch 36 | loss: 0.18471 | train_accuracy: 0.87491 | valid_accuracy: 0.83631 |  0:04:32s\n",
      "epoch 37 | loss: 0.19176 | train_accuracy: 0.88027 | valid_accuracy: 0.83517 |  0:04:39s\n",
      "epoch 38 | loss: 0.18832 | train_accuracy: 0.87434 | valid_accuracy: 0.83209 |  0:04:46s\n",
      "epoch 39 | loss: 0.19344 | train_accuracy: 0.87799 | valid_accuracy: 0.83631 |  0:04:54s\n",
      "epoch 40 | loss: 0.18679 | train_accuracy: 0.8784  | valid_accuracy: 0.83095 |  0:05:01s\n",
      "epoch 41 | loss: 0.18131 | train_accuracy: 0.87921 | valid_accuracy: 0.83404 |  0:05:08s\n",
      "epoch 42 | loss: 0.18551 | train_accuracy: 0.87759 | valid_accuracy: 0.8407  |  0:05:16s\n",
      "epoch 43 | loss: 0.18534 | train_accuracy: 0.87933 | valid_accuracy: 0.83891 |  0:05:23s\n",
      "epoch 44 | loss: 0.18225 | train_accuracy: 0.87743 | valid_accuracy: 0.83582 |  0:05:31s\n",
      "epoch 45 | loss: 0.17788 | train_accuracy: 0.87759 | valid_accuracy: 0.83339 |  0:05:38s\n",
      "epoch 46 | loss: 0.17957 | train_accuracy: 0.88132 | valid_accuracy: 0.83079 |  0:05:45s\n",
      "epoch 47 | loss: 0.18186 | train_accuracy: 0.8756  | valid_accuracy: 0.83128 |  0:05:53s\n",
      "epoch 48 | loss: 0.18571 | train_accuracy: 0.87617 | valid_accuracy: 0.82933 |  0:06:00s\n",
      "epoch 49 | loss: 0.19403 | train_accuracy: 0.87844 | valid_accuracy: 0.83972 |  0:06:07s\n",
      "epoch 50 | loss: 0.17924 | train_accuracy: 0.87877 | valid_accuracy: 0.8316  |  0:06:15s\n",
      "epoch 51 | loss: 0.17581 | train_accuracy: 0.88153 | valid_accuracy: 0.8329  |  0:06:22s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 1 and best_valid_accuracy = 0.85434\n",
      "Best weights from best epoch are automatically used!\n",
      "K-FOLD: 3\n",
      "epoch 0  | loss: 0.29467 | train_accuracy: 0.85656 | valid_accuracy: 0.85742 |  0:00:07s\n",
      "epoch 1  | loss: 0.28693 | train_accuracy: 0.85729 | valid_accuracy: 0.85011 |  0:00:14s\n",
      "epoch 2  | loss: 0.27413 | train_accuracy: 0.86224 | valid_accuracy: 0.84524 |  0:00:22s\n",
      "epoch 3  | loss: 0.27305 | train_accuracy: 0.85542 | valid_accuracy: 0.848   |  0:00:29s\n",
      "epoch 4  | loss: 0.25562 | train_accuracy: 0.86642 | valid_accuracy: 0.84475 |  0:00:37s\n",
      "epoch 5  | loss: 0.25268 | train_accuracy: 0.85806 | valid_accuracy: 0.84037 |  0:00:44s\n",
      "epoch 6  | loss: 0.26718 | train_accuracy: 0.86175 | valid_accuracy: 0.83777 |  0:00:51s\n",
      "epoch 7  | loss: 0.25513 | train_accuracy: 0.86768 | valid_accuracy: 0.84297 |  0:00:59s\n",
      "epoch 8  | loss: 0.25489 | train_accuracy: 0.86326 | valid_accuracy: 0.8454  |  0:01:06s\n",
      "epoch 9  | loss: 0.25329 | train_accuracy: 0.86139 | valid_accuracy: 0.84768 |  0:01:14s\n",
      "epoch 10 | loss: 0.23103 | train_accuracy: 0.86646 | valid_accuracy: 0.85109 |  0:01:21s\n",
      "epoch 11 | loss: 0.22416 | train_accuracy: 0.85924 | valid_accuracy: 0.84378 |  0:01:28s\n",
      "epoch 12 | loss: 0.25162 | train_accuracy: 0.86346 | valid_accuracy: 0.83988 |  0:01:36s\n",
      "epoch 13 | loss: 0.23389 | train_accuracy: 0.86638 | valid_accuracy: 0.83907 |  0:01:43s\n",
      "epoch 14 | loss: 0.22294 | train_accuracy: 0.86882 | valid_accuracy: 0.83988 |  0:01:50s\n",
      "epoch 15 | loss: 0.22989 | train_accuracy: 0.86788 | valid_accuracy: 0.84475 |  0:01:58s\n",
      "epoch 16 | loss: 0.22636 | train_accuracy: 0.86898 | valid_accuracy: 0.85011 |  0:02:05s\n",
      "epoch 17 | loss: 0.23199 | train_accuracy: 0.86529 | valid_accuracy: 0.8454  |  0:02:13s\n",
      "epoch 18 | loss: 0.22094 | train_accuracy: 0.86833 | valid_accuracy: 0.85304 |  0:02:20s\n",
      "epoch 19 | loss: 0.23763 | train_accuracy: 0.87276 | valid_accuracy: 0.84443 |  0:02:27s\n",
      "epoch 20 | loss: 0.22167 | train_accuracy: 0.86273 | valid_accuracy: 0.84313 |  0:02:35s\n",
      "epoch 21 | loss: 0.2273  | train_accuracy: 0.87544 | valid_accuracy: 0.84557 |  0:02:42s\n",
      "epoch 22 | loss: 0.21322 | train_accuracy: 0.87008 | valid_accuracy: 0.83923 |  0:02:50s\n",
      "epoch 23 | loss: 0.21504 | train_accuracy: 0.87418 | valid_accuracy: 0.84849 |  0:02:57s\n",
      "epoch 24 | loss: 0.21205 | train_accuracy: 0.87105 | valid_accuracy: 0.83111 |  0:03:04s\n",
      "epoch 25 | loss: 0.20762 | train_accuracy: 0.87791 | valid_accuracy: 0.84118 |  0:03:12s\n",
      "epoch 26 | loss: 0.20261 | train_accuracy: 0.86805 | valid_accuracy: 0.8467  |  0:03:19s\n",
      "epoch 27 | loss: 0.20323 | train_accuracy: 0.87    | valid_accuracy: 0.84622 |  0:03:26s\n",
      "epoch 28 | loss: 0.20341 | train_accuracy: 0.86805 | valid_accuracy: 0.84086 |  0:03:34s\n",
      "epoch 29 | loss: 0.21582 | train_accuracy: 0.87081 | valid_accuracy: 0.84654 |  0:03:41s\n",
      "epoch 30 | loss: 0.19709 | train_accuracy: 0.87402 | valid_accuracy: 0.8519  |  0:03:48s\n",
      "epoch 31 | loss: 0.19828 | train_accuracy: 0.87592 | valid_accuracy: 0.83875 |  0:03:56s\n",
      "epoch 32 | loss: 0.19915 | train_accuracy: 0.87787 | valid_accuracy: 0.8506  |  0:04:03s\n",
      "epoch 33 | loss: 0.18671 | train_accuracy: 0.87836 | valid_accuracy: 0.84167 |  0:04:10s\n",
      "epoch 34 | loss: 0.20385 | train_accuracy: 0.87048 | valid_accuracy: 0.84492 |  0:04:17s\n",
      "epoch 35 | loss: 0.19506 | train_accuracy: 0.87365 | valid_accuracy: 0.83956 |  0:04:25s\n",
      "epoch 36 | loss: 0.19084 | train_accuracy: 0.8745  | valid_accuracy: 0.85174 |  0:04:32s\n",
      "epoch 37 | loss: 0.19489 | train_accuracy: 0.87519 | valid_accuracy: 0.848   |  0:04:40s\n",
      "epoch 38 | loss: 0.19246 | train_accuracy: 0.87836 | valid_accuracy: 0.84914 |  0:04:47s\n",
      "epoch 39 | loss: 0.19848 | train_accuracy: 0.87775 | valid_accuracy: 0.84768 |  0:04:54s\n",
      "epoch 40 | loss: 0.18726 | train_accuracy: 0.87917 | valid_accuracy: 0.84297 |  0:05:02s\n",
      "epoch 41 | loss: 0.18221 | train_accuracy: 0.8784  | valid_accuracy: 0.84102 |  0:05:09s\n",
      "epoch 42 | loss: 0.18794 | train_accuracy: 0.87531 | valid_accuracy: 0.84784 |  0:05:17s\n",
      "epoch 43 | loss: 0.18413 | train_accuracy: 0.87479 | valid_accuracy: 0.84573 |  0:05:24s\n",
      "epoch 44 | loss: 0.19253 | train_accuracy: 0.87852 | valid_accuracy: 0.84086 |  0:05:32s\n",
      "epoch 45 | loss: 0.18993 | train_accuracy: 0.87812 | valid_accuracy: 0.83826 |  0:05:40s\n",
      "epoch 46 | loss: 0.18199 | train_accuracy: 0.87458 | valid_accuracy: 0.83469 |  0:05:47s\n",
      "epoch 47 | loss: 0.18253 | train_accuracy: 0.88205 | valid_accuracy: 0.84005 |  0:05:55s\n",
      "epoch 48 | loss: 0.18076 | train_accuracy: 0.88047 | valid_accuracy: 0.84037 |  0:06:02s\n",
      "epoch 49 | loss: 0.18735 | train_accuracy: 0.8795  | valid_accuracy: 0.84881 |  0:06:10s\n",
      "epoch 50 | loss: 0.17804 | train_accuracy: 0.88197 | valid_accuracy: 0.84394 |  0:06:17s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 0 and best_valid_accuracy = 0.85742\n",
      "Best weights from best epoch are automatically used!\n",
      "K-FOLD: 4\n",
      "epoch 0  | loss: 0.28816 | train_accuracy: 0.86221 | valid_accuracy: 0.85902 |  0:00:07s\n",
      "epoch 1  | loss: 0.28674 | train_accuracy: 0.85429 | valid_accuracy: 0.85626 |  0:00:14s\n",
      "epoch 2  | loss: 0.26691 | train_accuracy: 0.86269 | valid_accuracy: 0.85545 |  0:00:21s\n",
      "epoch 3  | loss: 0.25995 | train_accuracy: 0.85867 | valid_accuracy: 0.85594 |  0:00:29s\n",
      "epoch 4  | loss: 0.24683 | train_accuracy: 0.86387 | valid_accuracy: 0.85512 |  0:00:36s\n",
      "epoch 5  | loss: 0.24713 | train_accuracy: 0.86371 | valid_accuracy: 0.85415 |  0:00:44s\n",
      "epoch 6  | loss: 0.26247 | train_accuracy: 0.85798 | valid_accuracy: 0.84911 |  0:00:51s\n",
      "epoch 7  | loss: 0.2558  | train_accuracy: 0.85599 | valid_accuracy: 0.84181 |  0:00:58s\n",
      "epoch 8  | loss: 0.25215 | train_accuracy: 0.86679 | valid_accuracy: 0.85074 |  0:01:06s\n",
      "epoch 9  | loss: 0.24363 | train_accuracy: 0.85973 | valid_accuracy: 0.84034 |  0:01:13s\n",
      "epoch 10 | loss: 0.23378 | train_accuracy: 0.86972 | valid_accuracy: 0.85025 |  0:01:20s\n",
      "epoch 11 | loss: 0.23584 | train_accuracy: 0.86655 | valid_accuracy: 0.84635 |  0:01:28s\n",
      "epoch 12 | loss: 0.22661 | train_accuracy: 0.86318 | valid_accuracy: 0.84246 |  0:01:35s\n",
      "epoch 13 | loss: 0.22451 | train_accuracy: 0.87288 | valid_accuracy: 0.85415 |  0:01:43s\n",
      "epoch 14 | loss: 0.23505 | train_accuracy: 0.86773 | valid_accuracy: 0.847   |  0:01:50s\n",
      "epoch 15 | loss: 0.22145 | train_accuracy: 0.86562 | valid_accuracy: 0.84554 |  0:01:57s\n",
      "epoch 16 | loss: 0.22689 | train_accuracy: 0.86326 | valid_accuracy: 0.84798 |  0:02:05s\n",
      "epoch 17 | loss: 0.23187 | train_accuracy: 0.87085 | valid_accuracy: 0.84652 |  0:02:12s\n",
      "epoch 18 | loss: 0.21942 | train_accuracy: 0.8657  | valid_accuracy: 0.84538 |  0:02:19s\n",
      "epoch 19 | loss: 0.22443 | train_accuracy: 0.8741  | valid_accuracy: 0.85431 |  0:02:27s\n",
      "epoch 20 | loss: 0.20841 | train_accuracy: 0.87207 | valid_accuracy: 0.84717 |  0:02:34s\n",
      "epoch 21 | loss: 0.20455 | train_accuracy: 0.86797 | valid_accuracy: 0.84002 |  0:02:41s\n",
      "epoch 22 | loss: 0.22114 | train_accuracy: 0.87232 | valid_accuracy: 0.84489 |  0:02:49s\n",
      "epoch 23 | loss: 0.21054 | train_accuracy: 0.8767  | valid_accuracy: 0.85025 |  0:02:56s\n",
      "epoch 24 | loss: 0.2064  | train_accuracy: 0.8698  | valid_accuracy: 0.8444  |  0:03:04s\n",
      "epoch 25 | loss: 0.20163 | train_accuracy: 0.87244 | valid_accuracy: 0.84246 |  0:03:11s\n",
      "epoch 26 | loss: 0.20847 | train_accuracy: 0.8696  | valid_accuracy: 0.83904 |  0:03:18s\n",
      "epoch 27 | loss: 0.20949 | train_accuracy: 0.86931 | valid_accuracy: 0.84116 |  0:03:25s\n",
      "epoch 28 | loss: 0.20947 | train_accuracy: 0.87662 | valid_accuracy: 0.84765 |  0:03:33s\n",
      "epoch 29 | loss: 0.20743 | train_accuracy: 0.87126 | valid_accuracy: 0.84587 |  0:03:40s\n",
      "epoch 30 | loss: 0.20974 | train_accuracy: 0.87288 | valid_accuracy: 0.84489 |  0:03:48s\n",
      "epoch 31 | loss: 0.19868 | train_accuracy: 0.87463 | valid_accuracy: 0.8457  |  0:03:55s\n",
      "epoch 32 | loss: 0.20603 | train_accuracy: 0.86891 | valid_accuracy: 0.84294 |  0:04:02s\n",
      "epoch 33 | loss: 0.19899 | train_accuracy: 0.87593 | valid_accuracy: 0.84376 |  0:04:10s\n",
      "epoch 34 | loss: 0.19512 | train_accuracy: 0.87508 | valid_accuracy: 0.84148 |  0:04:17s\n",
      "epoch 35 | loss: 0.18823 | train_accuracy: 0.8765  | valid_accuracy: 0.847   |  0:04:25s\n",
      "epoch 36 | loss: 0.18999 | train_accuracy: 0.87386 | valid_accuracy: 0.84554 |  0:04:32s\n",
      "epoch 37 | loss: 0.18766 | train_accuracy: 0.58585 | valid_accuracy: 0.57463 |  0:04:39s\n",
      "epoch 38 | loss: 0.18635 | train_accuracy: 0.87366 | valid_accuracy: 0.84067 |  0:04:47s\n",
      "epoch 39 | loss: 0.1912  | train_accuracy: 0.87694 | valid_accuracy: 0.85074 |  0:04:54s\n",
      "epoch 40 | loss: 0.18746 | train_accuracy: 0.87869 | valid_accuracy: 0.84083 |  0:05:02s\n",
      "epoch 41 | loss: 0.18568 | train_accuracy: 0.87638 | valid_accuracy: 0.84229 |  0:05:09s\n",
      "epoch 42 | loss: 0.17737 | train_accuracy: 0.87731 | valid_accuracy: 0.84376 |  0:05:17s\n",
      "epoch 43 | loss: 0.17262 | train_accuracy: 0.87914 | valid_accuracy: 0.84018 |  0:05:24s\n",
      "epoch 44 | loss: 0.18637 | train_accuracy: 0.87585 | valid_accuracy: 0.84246 |  0:05:31s\n",
      "epoch 45 | loss: 0.18091 | train_accuracy: 0.88048 | valid_accuracy: 0.83823 |  0:05:38s\n",
      "epoch 46 | loss: 0.18414 | train_accuracy: 0.87642 | valid_accuracy: 0.84603 |  0:05:46s\n",
      "epoch 47 | loss: 0.18918 | train_accuracy: 0.87495 | valid_accuracy: 0.84505 |  0:05:53s\n",
      "epoch 48 | loss: 0.17576 | train_accuracy: 0.87613 | valid_accuracy: 0.83775 |  0:06:01s\n",
      "epoch 49 | loss: 0.18143 | train_accuracy: 0.84528 | valid_accuracy: 0.81598 |  0:06:08s\n",
      "epoch 50 | loss: 0.1806  | train_accuracy: 0.87654 | valid_accuracy: 0.84213 |  0:06:16s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 0 and best_valid_accuracy = 0.85902\n",
      "Best weights from best epoch are automatically used!\n",
      "K-FOLD: 5\n",
      "epoch 0  | loss: 0.29381 | train_accuracy: 0.85616 | valid_accuracy: 0.85382 |  0:00:07s\n",
      "epoch 1  | loss: 0.26771 | train_accuracy: 0.85766 | valid_accuracy: 0.8548  |  0:00:14s\n",
      "epoch 2  | loss: 0.27484 | train_accuracy: 0.80788 | valid_accuracy: 0.80461 |  0:00:22s\n",
      "epoch 3  | loss: 0.25807 | train_accuracy: 0.85876 | valid_accuracy: 0.85058 |  0:00:29s\n",
      "epoch 4  | loss: 0.24462 | train_accuracy: 0.86087 | valid_accuracy: 0.85106 |  0:00:36s\n",
      "epoch 5  | loss: 0.26122 | train_accuracy: 0.86176 | valid_accuracy: 0.84993 |  0:00:44s\n",
      "epoch 6  | loss: 0.24283 | train_accuracy: 0.86403 | valid_accuracy: 0.84928 |  0:00:51s\n",
      "epoch 7  | loss: 0.26132 | train_accuracy: 0.86452 | valid_accuracy: 0.84976 |  0:00:58s\n",
      "epoch 8  | loss: 0.25103 | train_accuracy: 0.86269 | valid_accuracy: 0.84327 |  0:01:06s\n",
      "epoch 9  | loss: 0.24641 | train_accuracy: 0.85051 | valid_accuracy: 0.83515 |  0:01:13s\n",
      "epoch 10 | loss: 0.2395  | train_accuracy: 0.86826 | valid_accuracy: 0.85009 |  0:01:21s\n",
      "epoch 11 | loss: 0.24327 | train_accuracy: 0.86079 | valid_accuracy: 0.83953 |  0:01:28s\n",
      "epoch 12 | loss: 0.23138 | train_accuracy: 0.8698  | valid_accuracy: 0.84944 |  0:01:35s\n",
      "epoch 13 | loss: 0.22285 | train_accuracy: 0.86854 | valid_accuracy: 0.84717 |  0:01:43s\n",
      "epoch 14 | loss: 0.21898 | train_accuracy: 0.86671 | valid_accuracy: 0.84034 |  0:01:50s\n",
      "epoch 15 | loss: 0.21583 | train_accuracy: 0.86951 | valid_accuracy: 0.84603 |  0:01:58s\n",
      "epoch 16 | loss: 0.22266 | train_accuracy: 0.85871 | valid_accuracy: 0.83645 |  0:02:05s\n",
      "epoch 17 | loss: 0.22296 | train_accuracy: 0.8696  | valid_accuracy: 0.84424 |  0:02:13s\n",
      "epoch 18 | loss: 0.23022 | train_accuracy: 0.86854 | valid_accuracy: 0.84376 |  0:02:20s\n",
      "epoch 19 | loss: 0.22793 | train_accuracy: 0.86326 | valid_accuracy: 0.83807 |  0:02:27s\n",
      "epoch 20 | loss: 0.21503 | train_accuracy: 0.8702  | valid_accuracy: 0.8483  |  0:02:35s\n",
      "epoch 21 | loss: 0.20448 | train_accuracy: 0.87301 | valid_accuracy: 0.84603 |  0:02:42s\n",
      "epoch 22 | loss: 0.20145 | train_accuracy: 0.86943 | valid_accuracy: 0.84213 |  0:02:50s\n",
      "epoch 23 | loss: 0.21431 | train_accuracy: 0.86939 | valid_accuracy: 0.84083 |  0:02:57s\n",
      "epoch 24 | loss: 0.20443 | train_accuracy: 0.87163 | valid_accuracy: 0.84376 |  0:03:05s\n",
      "epoch 25 | loss: 0.21224 | train_accuracy: 0.86391 | valid_accuracy: 0.83628 |  0:03:12s\n",
      "epoch 26 | loss: 0.20402 | train_accuracy: 0.87187 | valid_accuracy: 0.84278 |  0:03:20s\n",
      "epoch 27 | loss: 0.20366 | train_accuracy: 0.87089 | valid_accuracy: 0.84278 |  0:03:27s\n",
      "epoch 28 | loss: 0.20451 | train_accuracy: 0.87398 | valid_accuracy: 0.84164 |  0:03:35s\n",
      "epoch 29 | loss: 0.20202 | train_accuracy: 0.87357 | valid_accuracy: 0.84294 |  0:03:42s\n",
      "epoch 30 | loss: 0.20028 | train_accuracy: 0.87378 | valid_accuracy: 0.83969 |  0:03:49s\n",
      "epoch 31 | loss: 0.19956 | train_accuracy: 0.86639 | valid_accuracy: 0.83677 |  0:03:57s\n",
      "epoch 32 | loss: 0.18734 | train_accuracy: 0.87816 | valid_accuracy: 0.84993 |  0:04:04s\n",
      "epoch 33 | loss: 0.1931  | train_accuracy: 0.87422 | valid_accuracy: 0.84083 |  0:04:12s\n",
      "epoch 34 | loss: 0.18921 | train_accuracy: 0.87853 | valid_accuracy: 0.84814 |  0:04:19s\n",
      "epoch 35 | loss: 0.19015 | train_accuracy: 0.87361 | valid_accuracy: 0.83742 |  0:04:27s\n",
      "epoch 36 | loss: 0.19299 | train_accuracy: 0.87227 | valid_accuracy: 0.84213 |  0:04:34s\n",
      "epoch 37 | loss: 0.19707 | train_accuracy: 0.87179 | valid_accuracy: 0.83693 |  0:04:41s\n",
      "epoch 38 | loss: 0.18983 | train_accuracy: 0.87479 | valid_accuracy: 0.84359 |  0:04:49s\n",
      "epoch 39 | loss: 0.19444 | train_accuracy: 0.87479 | valid_accuracy: 0.84051 |  0:04:56s\n",
      "epoch 40 | loss: 0.18846 | train_accuracy: 0.87463 | valid_accuracy: 0.83515 |  0:05:04s\n",
      "epoch 41 | loss: 0.17432 | train_accuracy: 0.87869 | valid_accuracy: 0.8444  |  0:05:11s\n",
      "epoch 42 | loss: 0.17842 | train_accuracy: 0.87804 | valid_accuracy: 0.84164 |  0:05:18s\n",
      "epoch 43 | loss: 0.18126 | train_accuracy: 0.87167 | valid_accuracy: 0.82995 |  0:05:26s\n",
      "epoch 44 | loss: 0.18443 | train_accuracy: 0.87824 | valid_accuracy: 0.84083 |  0:05:33s\n",
      "epoch 45 | loss: 0.1856  | train_accuracy: 0.87455 | valid_accuracy: 0.83742 |  0:05:40s\n",
      "epoch 46 | loss: 0.18423 | train_accuracy: 0.87593 | valid_accuracy: 0.84164 |  0:05:48s\n",
      "epoch 47 | loss: 0.17769 | train_accuracy: 0.87841 | valid_accuracy: 0.84327 |  0:05:55s\n",
      "epoch 48 | loss: 0.18631 | train_accuracy: 0.87451 | valid_accuracy: 0.84489 |  0:06:02s\n",
      "epoch 49 | loss: 0.18315 | train_accuracy: 0.87877 | valid_accuracy: 0.83417 |  0:06:10s\n",
      "epoch 50 | loss: 0.17387 | train_accuracy: 0.87556 | valid_accuracy: 0.83986 |  0:06:17s\n",
      "epoch 51 | loss: 0.17347 | train_accuracy: 0.87849 | valid_accuracy: 0.84278 |  0:06:25s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 1 and best_valid_accuracy = 0.8548\n",
      "Best weights from best epoch are automatically used!\n",
      "MODEL PERFORMANCE\n",
      "K-FOLD 1 \t 0.8364728808054563\n",
      "K-FOLD 1 \t 0.8543358233192595\n",
      "K-FOLD 1 \t 0.8574212406625528\n",
      "K-FOLD 1 \t 0.8590222510963131\n",
      "K-FOLD 1 \t 0.854799415299659\n",
      "AVERAGE: 0.8524103222366481\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "CV_score_array = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"K-FOLD: {}\".format(i))\n",
    "    X_train, X_val = X[train_index], X[test_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[test_index]\n",
    "    clf1_nopreproc.fit(\n",
    "        X_train, Y_train,\n",
    "        eval_set=[(X_train, Y_train), (X_val, Y_val)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['accuracy'],\n",
    "        max_epochs=1000, patience=50,\n",
    "        batch_size=256, virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        weights=1,\n",
    "        drop_last=False\n",
    "    )\n",
    "    i += 1\n",
    "    CV_score_array.append(clf1_nopreproc.best_cost)\n",
    "\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "i = 1\n",
    "for score in CV_score_array:\n",
    "    print(\"K-FOLD {} \\t {}\".format(i, score))\n",
    "CV_mean = np.mean(CV_score_array)\n",
    "print(\"AVERAGE: {}\".format(CV_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31112bb",
   "metadata": {},
   "source": [
    "Testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "112b091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY: 0.8205794465376121%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "preds = clf1_nopreproc.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, preds)\n",
    "print('TEST ACCURACY: {}%'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
